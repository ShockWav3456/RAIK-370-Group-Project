{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Function to clean and split text into words\n",
    "def extract_words(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing non-alphabetic characters and \n",
    "    converting it to lowercase. Then, it splits the text into words.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The headline or text to process.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of words from the text.\n",
    "    \"\"\"\n",
    "    # Remove any non-alphabetic characters and convert to lowercase\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return words\n",
    "\n",
    "# 1) Function to separate sarcastic headlines from Sarcasm_Headlines_Dataset.json and add them into a DataFrame\n",
    "def process_sarcasm_json(json_file, df):\n",
    "    \"\"\"\n",
    "    Processes the Sarcasm_Headlines_Dataset.json file, extracting headlines \n",
    "    that are sarcastic (is_sarcastic == 1), and appends them to the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        json_file (str): The path to the JSON file containing sarcastic headlines.\n",
    "        df (DataFrame): The DataFrame to which sarcastic headlines will be added.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame containing sarcastic headlines.\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\") as file:\n",
    "        # Load the entire JSON array\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # Extract sarcastic headlines (is_sarcastic == 1)\n",
    "    new_rows = [{\"headline\": entry[\"headline\"]} for entry in data if entry[\"is_sarcastic\"] == 1]\n",
    "    \n",
    "    # Convert the list of new rows into a DataFrame and concatenate with the original DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 2) Function to separate sarcastic headlines from OnionOrNot.csv and add them into a DataFrame\n",
    "def process_onion_csv(csv_file, df):\n",
    "    \"\"\"\n",
    "    Processes the OnionOrNot.csv file, extracting sarcastic headlines (label == 1),\n",
    "    and appends them to the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_file (str): The path to the CSV file containing headlines and labels.\n",
    "        df (DataFrame): The DataFrame to which sarcastic headlines will be added.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame containing sarcastic headlines.\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        \n",
    "        for row in reader:\n",
    "            headline, label = row\n",
    "            try:\n",
    "                label = int(label)\n",
    "                # Only process sarcastic entries (label 1)\n",
    "                if label == 1:\n",
    "                    new_rows.append({\"headline\": headline})\n",
    "            except ValueError:\n",
    "                # In case there's an issue converting label to int, ignore that row\n",
    "                continue\n",
    "    \n",
    "    # Convert the list of new rows into a DataFrame and concatenate with the original DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 3) Function to count words from a DataFrame of headlines and update a word count object\n",
    "def count_words_from_dataframe(df, word_count):\n",
    "    \"\"\"\n",
    "    Counts the frequency of each word in the 'headline' column of the DataFrame \n",
    "    and updates the word_count Counter object.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the headlines.\n",
    "        word_count (Counter): The Counter object to update with word frequencies.\n",
    "    \n",
    "    Returns:\n",
    "        Counter: The updated word count object.\n",
    "    \"\"\"\n",
    "    for headline in df[\"headline\"]:\n",
    "        words = extract_words(headline)\n",
    "        word_count.update(words)\n",
    "    return word_count\n",
    "\n",
    "# 4) Function to write word counts to a text file\n",
    "def write_word_count_to_file(sorted_word_count, output_file):\n",
    "    \"\"\"\n",
    "    Writes the word frequency counts to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "        sorted_word_count (list): A sorted list of tuples (word, count).\n",
    "        output_file (str): The path to the output text file.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Word Frequency Count from Sarcastic Headlines:\\n\")\n",
    "        for word, count in sorted_word_count:\n",
    "            file.write(f\"{word}: {count}\\n\")\n",
    "            \n",
    "# 5)\n",
    "def sort_word_count(word_count, sort_type=\"frequency\", order=\"desc\"):\n",
    "    \"\"\"\n",
    "    Sorts the word count based on the specified sorting type and order.\n",
    "    \n",
    "    Parameters:\n",
    "        word_count (Counter): The Counter object containing word frequencies.\n",
    "        sort_type (str): The type of sorting to apply ('frequency' or 'length').\n",
    "        order (str): The order of sorting ('asc' for ascending, 'desc' for descending).\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples (word, count), sorted as specified.\n",
    "    \"\"\"\n",
    "    if sort_type == \"frequency\":\n",
    "        # Sort by word frequency (either most to least or least to most)\n",
    "        sorted_word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=(order==\"desc\"))\n",
    "    elif sort_type == \"length\":\n",
    "        # Sort by word length (either longest to shortest or shortest to longest)\n",
    "        sorted_word_count = sorted(word_count.items(), key=lambda x: len(x[0]), reverse=(order==\"desc\"))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sort_type. Choose 'frequency' or 'length'.\")\n",
    "    \n",
    "    return sorted_word_count\n",
    "\n",
    "\n",
    "# 9) Function to add a column to the DataFrame that stores the number of words in each headline\n",
    "def add_word_count_column(df):\n",
    "    \"\"\"\n",
    "    Adds a new column 'word_count' to the DataFrame, representing \n",
    "    the number of words in each headline.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'headline' column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame with a new 'word_count' column.\n",
    "    \"\"\"\n",
    "    if df.empty or 'headline' not in df.columns:\n",
    "        df['word_count'] = 0\n",
    "        return df\n",
    "\n",
    "    df['word_count'] = df['headline'].apply(lambda x: len(extract_words(x)))\n",
    "    return df\n",
    "\n",
    "# 11) Function to add a column to the DataFrame that stores the number of characters in each headline\n",
    "def add_char_count_column(df):\n",
    "    \"\"\"\n",
    "    Adds a new column 'char_count' to the DataFrame, representing \n",
    "    the number of characters in each headline (excluding leading/trailing spaces).\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'headline' column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame with a new 'char_count' column.\n",
    "    \"\"\"\n",
    "    if df.empty or 'headline' not in df.columns:\n",
    "        df['char_count'] = 0\n",
    "        return df\n",
    "\n",
    "    df['char_count'] = df['headline'].apply(lambda x: len(x.strip()))\n",
    "    return df\n",
    "\n",
    "# 13) Function to sort the DataFrame based on a specific column and order\n",
    "def sort_headlines_by_column(df, column_name, ascending=True):\n",
    "    \"\"\"\n",
    "    Sorts the DataFrame by the specified column and order (ascending or descending).\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to sort.\n",
    "        column_name (str): The column name to sort by (e.g., 'word_count' or 'char_count').\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The sorted DataFrame.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in DataFrame. Please ensure it exists.\")\n",
    "\n",
    "    sorted_df = df.sort_values(by=column_name, ascending=ascending).reset_index(drop=True)\n",
    "    return sorted_df\n",
    "\n",
    "# 14) Function to \n",
    "def write_sorted_df_to_file(df, output_file, column_name, ascending):\n",
    "    \"\"\"\n",
    "    Writes the sorted DataFrame to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to write to a file.\n",
    "        output_file (str): The path to the output text file.\n",
    "        column_name (str): The column name to use for sorting (e.g., 'word_count' or 'char_count').\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by the given column_name and ascending order\n",
    "    df_sorted = df.sort_values(by=column_name, ascending=ascending).reset_index(drop=True)\n",
    "    \n",
    "    order_title = \"ascending\" if ascending else \"descending\"\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        # Write the header to indicate sorting details\n",
    "        file.write(f\"Sorted Headlines by {column_name} ({order_title}):\\n\\n\")\n",
    "        \n",
    "        # Write the headlines to the file\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            file.write(f\"{row['headline']}\\n\")\n",
    "\n",
    "# 15) Function to count frequency of character counts and write to file\n",
    "def write_char_count_frequency_to_file(df, output_file, ascending=True):\n",
    "    \"\"\"\n",
    "    Writes the frequency of character counts to a file, sorted in either ascending or descending order.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'char_count' column.\n",
    "        output_file (str): The path to the output text file.\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "    \"\"\"\n",
    "    # Count the frequency of each character count\n",
    "    char_count_freq = df['char_count'].value_counts().sort_index(ascending=ascending)\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Character Count Frequency (sorted {'ascending' if ascending else 'descending'}):\\n\\n\")\n",
    "        \n",
    "        # Write the number of headlines for each character count\n",
    "        for char_count, count in char_count_freq.items():\n",
    "            file.write(f\"{char_count} character Headline: {count}\\n\")\n",
    "\n",
    "def write_word_count_frequency_to_file(df, output_file, ascending=True):\n",
    "    \"\"\"\n",
    "    Writes the frequency of word counts to a file, sorted in either ascending or descending order.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'headline' column.\n",
    "        output_file (str): The path to the output text file.\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "    \"\"\"\n",
    "    # First, add a word count column to the DataFrame\n",
    "    df = add_word_count_column(df)\n",
    "    \n",
    "    # Sort by word count using the provided function\n",
    "    sorted_df = sort_headlines_by_column(df, 'word_count', ascending)\n",
    "    \n",
    "    # Count the frequency of each word count\n",
    "    word_count_freq = sorted_df['word_count'].value_counts().sort_index(ascending=ascending)\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Word Count Frequency (sorted {'ascending' if ascending else 'descending'}):\\n\\n\")\n",
    "        \n",
    "        # Write the number of occurrences for each word count\n",
    "        for count, freq in word_count_freq.items():\n",
    "            file.write(f\"{count} word headline: {freq}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satire Headlines\n",
    "\n",
    "satire_source_path = \"./Data_Exploration/Satire_HeadLines_Source/\"\n",
    "satire_analysis_path = \"./Data_Exploration/Satire_Headlines_Analysis/\"\n",
    "\n",
    "#Display headlines with occurance of X number of Characters\n",
    "satire_analysis_healine_length_in_chars_path = satire_analysis_path + \"Headline_Occurances_By_Number_Of_Characters/\" #Correct\n",
    "#Displays headlines in order by number of characters\n",
    "satire_analysis_char_count_chars_path = satire_analysis_path + \"Headline_By_Number_Of_Characters_In_Headline/\" #Correct\n",
    "\n",
    "#Display headlines with occurance of X number of words\n",
    "satire_analysis_healine_length_in_words_path = satire_analysis_path + \"Headline_Occurances_By_Number_Of_Words/\" #Correct\n",
    "#Displays headlines in order by number of words\n",
    "satire_analysis_word_count_words_path = satire_analysis_path + \"Headline_By_Number_Of_Words_In_Headline/\" #Correct\n",
    "\n",
    "#Display words by occurance sorted by length\n",
    "satire_analysis_words_by_length_path = satire_analysis_path + \"Words_Occurance_By_Word_Length/\"\n",
    "#Displays headlines in order by number of words\n",
    "satire_analysis_word_by_count_path = satire_analysis_path + \"Words_Occurance_By_Word_Count/\" #Correct\n",
    "\n",
    "# Initialize an empty DataFrame to store sarcastic headlines\n",
    "satire_df = pd.DataFrame(columns=[\"headline\"])\n",
    "\n",
    "# Initialize the word count Counter\n",
    "word_count = Counter()\n",
    "\n",
    "# Process sarcastic headlines from the JSON file\n",
    "satire_df = process_sarcasm_json(satire_source_path + \"Fixed_Sarcasm_Headlines_Dataset.json\", satire_df)\n",
    "\n",
    "# Process sarcastic headlines from the CSV file\n",
    "satire_df = process_onion_csv(satire_source_path + \"OnionOrNot.csv\", satire_df)\n",
    "\n",
    "# Add word count and character count columns to the DataFrame\n",
    "length_df = add_word_count_column(satire_df)  # Ensure word_count is added here\n",
    "length_df = add_char_count_column(length_df)  # Add char_count if needed\n",
    "\n",
    "# Count words from the DataFrame\n",
    "word_count = count_words_from_dataframe(satire_df, word_count)\n",
    "\n",
    "# Example: To write sorted by character count frequency in ascending order\n",
    "write_char_count_frequency_to_file(length_df, satire_analysis_healine_length_in_chars_path + \"char_count_frequency_asc.txt\", ascending=True) #Correct\n",
    "\n",
    "# Example: To write sorted by character count frequency in descending order\n",
    "write_char_count_frequency_to_file(length_df, satire_analysis_healine_length_in_chars_path + \"char_count_frequency_desc.txt\", ascending=False) #Correct\n",
    "\n",
    "# Example: To write word count frequency sorted in ascending order\n",
    "write_word_count_frequency_to_file(length_df, satire_analysis_healine_length_in_words_path + \"headline_length_in_words_asc.txt\", ascending=True) #Correct\n",
    "\n",
    "# Example: To write word count frequency sorted in descending order\n",
    "write_word_count_frequency_to_file(length_df, satire_analysis_healine_length_in_words_path + \"headline_length_in_words_desc.txt\", ascending=False) #Correct\n",
    "\n",
    "# Sort the DataFrame by word count in descending order\n",
    "sorted_by_words_desc = sort_headlines_by_column(length_df, 'word_count', ascending=False)\n",
    "write_sorted_df_to_file(sorted_by_words_desc, satire_analysis_word_count_words_path + \"sorted_by_word_count_desc.txt\", \"word_count\", ascending=False) #Correct\n",
    "\n",
    "# Sort the DataFrame by word count in ascending order\n",
    "sorted_by_words_asc = sort_headlines_by_column(length_df, 'word_count', ascending=True)\n",
    "write_sorted_df_to_file(sorted_by_words_asc, satire_analysis_word_count_words_path + \"sorted_by_word_count_asc.txt\", \"word_count\", ascending=True) #Correct\n",
    "\n",
    "# Sort the DataFrame by character count in descending order\n",
    "sorted_by_chars_desc = sort_headlines_by_column(length_df, 'char_count', ascending=False)\n",
    "write_sorted_df_to_file(sorted_by_chars_desc, satire_analysis_char_count_chars_path + \"sorted_by_char_count_desc.txt\", \"char_count\", ascending=False) #Correct\n",
    "\n",
    "# Sort the DataFrame by character count in ascending order\n",
    "sorted_by_chars_asc = sort_headlines_by_column(length_df, 'char_count', ascending=True)\n",
    "write_sorted_df_to_file(sorted_by_chars_asc, satire_analysis_char_count_chars_path + \"sorted_by_char_count_asc.txt\", \"char_count\", ascending=True) #Correct\n",
    "\n",
    "# Sort the word counts and write to a file\n",
    "# Sort by word count, most to least (descending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"frequency\", order=\"desc\")\n",
    "write_word_count_to_file(sorted_word_count, satire_analysis_word_by_count_path + \"word_count_most_to_least.txt\")\n",
    "\n",
    "# Sort by word count, least to most (ascending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"frequency\", order=\"asc\")\n",
    "write_word_count_to_file(sorted_word_count, satire_analysis_word_by_count_path + \"word_count_least_to_most.txt\")\n",
    "\n",
    "# Sort by word length, longest to shortest (descending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"length\", order=\"desc\")\n",
    "write_word_count_to_file(sorted_word_count, satire_analysis_words_by_length_path + \"word_length_longest_to_shortest.txt\")\n",
    "\n",
    "# Sort by word length, shortest to longest (ascending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"length\", order=\"asc\")\n",
    "write_word_count_to_file(sorted_word_count, satire_analysis_words_by_length_path + \"word_length_shortest_to_longest.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_true_csv(file_path, df):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Print the actual column names to check for hidden characters or spaces\n",
    "    print(\"Original columns:\", df.columns)\n",
    "    \n",
    "    # Strip any leading/trailing spaces from column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Rename 'title' to 'headline' if it exists\n",
    "    if 'title' in df.columns:\n",
    "        df.rename(columns={'title': 'headline'}, inplace=True)\n",
    "        print(\"Renamed 'title' to 'headline'\")\n",
    "    else:\n",
    "        print(\"No column named 'title' to rename!\")\n",
    "    \n",
    "    # Keep only the 'headline' column and drop the rest\n",
    "    if 'headline' in df.columns:\n",
    "        df = df[['headline']]  # This keeps only the 'headline' column\n",
    "        print(\"Kept only 'headline' column\")\n",
    "    else:\n",
    "        print(\"No 'headline' column found after renaming!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def count_words_from_dataframe(df, word_count):\n",
    "    for index, row in df.iterrows():\n",
    "        headline = row['headline']  # Make sure we are accessing 'headline'\n",
    "        word_count.update(headline.split())  # Update the word count\n",
    "    return word_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: Index(['title', 'text', 'subject', 'date'], dtype='object')\n",
      "Renamed 'title' to 'headline'\n",
      "Kept only 'headline' column\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m genuine_df = add_char_count_column(genuine_df)  \u001b[38;5;66;03m# Add char_count if needed\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Count words from the DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m word_count = \u001b[43mcount_words_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenuine_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Example: To write sorted by character count frequency in ascending order\u001b[39;00m\n\u001b[32m     34\u001b[39m write_char_count_frequency_to_file(genuine_df, genuine_analysis_healine_length_in_chars_path + \u001b[33m\"\u001b[39m\u001b[33mchar_count_frequency_asc.txt\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcount_words_from_dataframe\u001b[39m\u001b[34m(df, word_count)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcount_words_from_dataframe\u001b[39m(df, word_count):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m title \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m:  \u001b[38;5;66;03m# Assuming 'title' is the correct column name\u001b[39;00m\n\u001b[32m      4\u001b[39m         word_count.update(title.split())\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m word_count\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'title'"
     ]
    }
   ],
   "source": [
    "# Genuine Headlines\n",
    "genuine_source_path = \"./Data_Exploration/Genuine_HeadLines_Source/\"\n",
    "genuine_analysis_path = \"./Data_Exploration/Genuine_Headlines_Analysis/\"\n",
    "\n",
    "# Path for genuine headline analysis\n",
    "genuine_analysis_healine_length_in_chars_path = genuine_analysis_path + \"Headline_Occurances_By_Number_Of_Characters/\"\n",
    "genuine_analysis_char_count_chars_path = genuine_analysis_path + \"Headline_By_Number_Of_Characters_In_Headline/\"\n",
    "\n",
    "# Display headlines with occurrence of X number of words\n",
    "genuine_analysis_healine_length_in_words_path = genuine_analysis_path + \"Headline_Occurances_By_Number_Of_Words/\"\n",
    "genuine_analysis_word_count_words_path = genuine_analysis_path + \"Headline_By_Number_Of_Words_In_Headline/\"\n",
    "\n",
    "# Display words by occurrence sorted by length\n",
    "genuine_analysis_words_by_length_path = genuine_analysis_path + \"Words_Occurance_By_Word_Length/\"\n",
    "genuine_analysis_word_by_count_path = genuine_analysis_path + \"Words_Occurance_By_Word_Count/\"\n",
    "\n",
    "# Initialize an empty DataFrame for genuine headlines\n",
    "genuine_df = pd.DataFrame()\n",
    "\n",
    "# Initialize word count Counter\n",
    "word_count = Counter()\n",
    "\n",
    "# Process genuine headlines from the CSV file\n",
    "genuine_df = process_true_csv(genuine_source_path + \"True.csv\", genuine_df)\n",
    "\n",
    "# Add word count and character count columns to the DataFrame\n",
    "genuine_df = add_word_count_column(genuine_df)  # Ensure word_count is added here\n",
    "genuine_df = add_char_count_column(genuine_df)  # Add char_count if needed\n",
    "\n",
    "# Count words from the DataFrame\n",
    "word_count = count_words_from_dataframe(genuine_df, word_count)\n",
    "\n",
    "# Example: To write sorted by character count frequency in ascending order\n",
    "write_char_count_frequency_to_file(genuine_df, genuine_analysis_healine_length_in_chars_path + \"char_count_frequency_asc.txt\", ascending=True)\n",
    "\n",
    "# Example: To write sorted by character count frequency in descending order\n",
    "write_char_count_frequency_to_file(genuine_df, genuine_analysis_healine_length_in_chars_path + \"char_count_frequency_desc.txt\", ascending=False)\n",
    "\n",
    "# Example: To write word count frequency sorted in ascending order\n",
    "write_word_count_frequency_to_file(genuine_df, genuine_analysis_healine_length_in_words_path + \"headline_length_in_words_asc.txt\", ascending=True)\n",
    "\n",
    "# Example: To write word count frequency sorted in descending order\n",
    "write_word_count_frequency_to_file(genuine_df, genuine_analysis_healine_length_in_words_path + \"headline_length_in_words_desc.txt\", ascending=False)\n",
    "\n",
    "# Sort the DataFrame by word count in descending order\n",
    "sorted_by_words_desc = sort_headlines_by_column(genuine_df, 'word_count', ascending=False)\n",
    "write_sorted_df_to_file(sorted_by_words_desc, genuine_analysis_word_count_words_path + \"sorted_by_word_count_desc.txt\", \"word_count\", ascending=False)\n",
    "\n",
    "# Sort the DataFrame by word count in ascending order\n",
    "sorted_by_words_asc = sort_headlines_by_column(genuine_df, 'word_count', ascending=True)\n",
    "write_sorted_df_to_file(sorted_by_words_asc, genuine_analysis_word_count_words_path + \"sorted_by_word_count_asc.txt\", \"word_count\", ascending=True)\n",
    "\n",
    "# Sort the DataFrame by character count in descending order\n",
    "sorted_by_chars_desc = sort_headlines_by_column(genuine_df, 'char_count', ascending=False)\n",
    "write_sorted_df_to_file(sorted_by_chars_desc, genuine_analysis_char_count_chars_path + \"sorted_by_char_count_desc.txt\", \"char_count\", ascending=False)\n",
    "\n",
    "# Sort the DataFrame by character count in ascending order\n",
    "sorted_by_chars_asc = sort_headlines_by_column(genuine_df, 'char_count', ascending=True)\n",
    "write_sorted_df_to_file(sorted_by_chars_asc, genuine_analysis_char_count_chars_path + \"sorted_by_char_count_asc.txt\", \"char_count\", ascending=True)\n",
    "\n",
    "# Sort the word counts and write to a file\n",
    "# Sort by word count, most to least (descending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"frequency\", order=\"desc\")\n",
    "write_word_count_to_file(sorted_word_count, genuine_analysis_word_by_count_path + \"word_count_most_to_least.txt\")\n",
    "\n",
    "# Sort by word count, least to most (ascending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"frequency\", order=\"asc\")\n",
    "write_word_count_to_file(sorted_word_count, genuine_analysis_word_by_count_path + \"word_count_least_to_most.txt\")\n",
    "\n",
    "# Sort by word length, longest to shortest (descending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"length\", order=\"desc\")\n",
    "write_word_count_to_file(sorted_word_count, genuine_analysis_words_by_length_path + \"word_length_longest_to_shortest.txt\")\n",
    "\n",
    "# Sort by word length, shortest to longest (ascending)\n",
    "sorted_word_count = sort_word_count(word_count, sort_type=\"length\", order=\"asc\")\n",
    "write_word_count_to_file(sorted_word_count, genuine_analysis_words_by_length_path + \"word_length_shortest_to_longest.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Function to clean and split text into words\n",
    "def extract_words(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by removing non-alphabetic characters and \n",
    "    converting it to lowercase. Then, it splits the text into words.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The headline or text to process.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of words from the text.\n",
    "    \"\"\"\n",
    "    # Remove any non-alphabetic characters and convert to lowercase\n",
    "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "    return words\n",
    "\n",
    "# 1) Function to separate sarcastic headlines from Sarcasm_Headlines_Dataset.json and add them into a DataFrame\n",
    "def process_sarcasm_json(json_file, df):\n",
    "    \"\"\"\n",
    "    Processes the Sarcasm_Headlines_Dataset.json file, extracting headlines \n",
    "    that are sarcastic (is_sarcastic == 1), and appends them to the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        json_file (str): The path to the JSON file containing sarcastic headlines.\n",
    "        df (DataFrame): The DataFrame to which sarcastic headlines will be added.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame containing sarcastic headlines.\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\") as file:\n",
    "        # Load the entire JSON array\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # Extract sarcastic headlines (is_sarcastic == 1)\n",
    "    new_rows = [{\"headline\": entry[\"headline\"]} for entry in data if entry[\"is_sarcastic\"] == 1]\n",
    "    \n",
    "    # Convert the list of new rows into a DataFrame and concatenate with the original DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 2) Function to separate sarcastic headlines from OnionOrNot.csv and add them into a DataFrame\n",
    "def process_onion_csv(csv_file, df):\n",
    "    \"\"\"\n",
    "    Processes the OnionOrNot.csv file, extracting sarcastic headlines (label == 1),\n",
    "    and appends them to the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_file (str): The path to the CSV file containing headlines and labels.\n",
    "        df (DataFrame): The DataFrame to which sarcastic headlines will be added.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame containing sarcastic headlines.\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "    with open(csv_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        \n",
    "        for row in reader:\n",
    "            headline, label = row\n",
    "            try:\n",
    "                label = int(label)\n",
    "                # Only process sarcastic entries (label 1)\n",
    "                if label == 1:\n",
    "                    new_rows.append({\"headline\": headline})\n",
    "            except ValueError:\n",
    "                # In case there's an issue converting label to int, ignore that row\n",
    "                continue\n",
    "    \n",
    "    # Convert the list of new rows into a DataFrame and concatenate with the original DataFrame\n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 3) Function to count words from a DataFrame of headlines and update a word count object\n",
    "def count_words_from_dataframe(df, word_count):\n",
    "    \"\"\"\n",
    "    Counts the frequency of each word in the 'headline' column of the DataFrame \n",
    "    and updates the word_count Counter object.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the headlines.\n",
    "        word_count (Counter): The Counter object to update with word frequencies.\n",
    "    \n",
    "    Returns:\n",
    "        Counter: The updated word count object.\n",
    "    \"\"\"\n",
    "    for headline in df[\"headline\"]:\n",
    "        words = extract_words(headline)\n",
    "        word_count.update(words)\n",
    "    return word_count\n",
    "\n",
    "# 4) Function to write word counts to a text file\n",
    "def write_word_count_to_file(sorted_word_count, output_file):\n",
    "    \"\"\"\n",
    "    Writes the word frequency counts to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "        sorted_word_count (list): A sorted list of tuples (word, count).\n",
    "        output_file (str): The path to the output text file.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"Word Frequency Count from Sarcastic Headlines:\\n\")\n",
    "        for word, count in sorted_word_count:\n",
    "            file.write(f\"{word}: {count}\\n\")\n",
    "            \n",
    "# 5)\n",
    "def sort_word_count(word_count, sort_type=\"frequency\", order=\"desc\"):\n",
    "    \"\"\"\n",
    "    Sorts the word count based on the specified sorting type and order.\n",
    "    \n",
    "    Parameters:\n",
    "        word_count (Counter): The Counter object containing word frequencies.\n",
    "        sort_type (str): The type of sorting to apply ('frequency' or 'length').\n",
    "        order (str): The order of sorting ('asc' for ascending, 'desc' for descending).\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples (word, count), sorted as specified.\n",
    "    \"\"\"\n",
    "    if sort_type == \"frequency\":\n",
    "        # Sort by word frequency (either most to least or least to most)\n",
    "        sorted_word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=(order==\"desc\"))\n",
    "    elif sort_type == \"length\":\n",
    "        # Sort by word length (either longest to shortest or shortest to longest)\n",
    "        sorted_word_count = sorted(word_count.items(), key=lambda x: len(x[0]), reverse=(order==\"desc\"))\n",
    "    else:\n",
    "        raise ValueError(\"Invalid sort_type. Choose 'frequency' or 'length'.\")\n",
    "    \n",
    "    return sorted_word_count\n",
    "\n",
    "\n",
    "# 9) Function to add a column to the DataFrame that stores the number of words in each headline\n",
    "def add_word_count_column(df):\n",
    "    \"\"\"\n",
    "    Adds a new column 'word_count' to the DataFrame, representing \n",
    "    the number of words in each headline.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'headline' column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame with a new 'word_count' column.\n",
    "    \"\"\"\n",
    "    if df.empty or 'headline' not in df.columns:\n",
    "        df['word_count'] = 0\n",
    "        return df\n",
    "\n",
    "    df['word_count'] = df['headline'].apply(lambda x: len(extract_words(x)))\n",
    "    return df\n",
    "\n",
    "# 11) Function to add a column to the DataFrame that stores the number of characters in each headline\n",
    "def add_char_count_column(df):\n",
    "    \"\"\"\n",
    "    Adds a new column 'char_count' to the DataFrame, representing \n",
    "    the number of characters in each headline (excluding leading/trailing spaces).\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'headline' column.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame with a new 'char_count' column.\n",
    "    \"\"\"\n",
    "    if df.empty or 'headline' not in df.columns:\n",
    "        df['char_count'] = 0\n",
    "        return df\n",
    "\n",
    "    df['char_count'] = df['headline'].apply(lambda x: len(x.strip()))\n",
    "    return df\n",
    "\n",
    "# 13) Function to sort the DataFrame based on a specific column and order\n",
    "def sort_headlines_by_column(df, column_name, ascending=True):\n",
    "    \"\"\"\n",
    "    Sorts the DataFrame by the specified column and order (ascending or descending).\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to sort.\n",
    "        column_name (str): The column name to sort by (e.g., 'word_count' or 'char_count').\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The sorted DataFrame.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in DataFrame. Please ensure it exists.\")\n",
    "\n",
    "    sorted_df = df.sort_values(by=column_name, ascending=ascending).reset_index(drop=True)\n",
    "    return sorted_df\n",
    "\n",
    "# 14) Function to \n",
    "def write_sorted_df_to_file(df, output_file, column_name, ascending):\n",
    "    \"\"\"\n",
    "    Writes the sorted DataFrame to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame to write to a file.\n",
    "        output_file (str): The path to the output text file.\n",
    "        column_name (str): The column name to use for sorting (e.g., 'word_count' or 'char_count').\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "    \"\"\"\n",
    "    # Sort the DataFrame by the given column_name and ascending order\n",
    "    df_sorted = df.sort_values(by=column_name, ascending=ascending).reset_index(drop=True)\n",
    "    \n",
    "    order_title = \"ascending\" if ascending else \"descending\"\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        # Write the header to indicate sorting details\n",
    "        file.write(f\"Sorted Headlines by {column_name} ({order_title}):\\n\\n\")\n",
    "        \n",
    "        # Write the headlines to the file\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            file.write(f\"{row['headline']}\\n\")\n",
    "\n",
    "# 15) Function to count frequency of character counts and write to file\n",
    "def write_char_count_frequency_to_file(df, output_file, ascending=True):\n",
    "    \"\"\"\n",
    "    Writes the frequency of character counts to a file, sorted in either ascending or descending order.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'char_count' column.\n",
    "        output_file (str): The path to the output text file.\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "    \"\"\"\n",
    "    # Count the frequency of each character count\n",
    "    char_count_freq = df['char_count'].value_counts().sort_index(ascending=ascending)\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Character Count Frequency (sorted {'ascending' if ascending else 'descending'}):\\n\\n\")\n",
    "        \n",
    "        # Write the number of headlines for each character count\n",
    "        for char_count, count in char_count_freq.items():\n",
    "            file.write(f\"{char_count} character Headline: {count}\\n\")\n",
    "\n",
    "def write_word_count_frequency_to_file(df, output_file, ascending=True):\n",
    "    \"\"\"\n",
    "    Writes the frequency of word counts to a file, sorted in either ascending or descending order.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The DataFrame containing the 'headline' column.\n",
    "        output_file (str): The path to the output text file.\n",
    "        ascending (bool): If True, sorts in ascending order; if False, sorts in descending order.\n",
    "    \"\"\"\n",
    "    # First, add a word count column to the DataFrame\n",
    "    df = add_word_count_column(df)\n",
    "    \n",
    "    # Sort by word count using the provided function\n",
    "    sorted_df = sort_headlines_by_column(df, 'word_count', ascending)\n",
    "    \n",
    "    # Count the frequency of each word count\n",
    "    word_count_freq = sorted_df['word_count'].value_counts().sort_index(ascending=ascending)\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Word Count Frequency (sorted {'ascending' if ascending else 'descending'}):\\n\\n\")\n",
    "        \n",
    "        # Write the number of occurrences for each word count\n",
    "        for count, freq in word_count_freq.items():\n",
    "            file.write(f\"{count} word headline: {freq}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Data_Exploration/Satire_HeadLines_Source/Sarcasm_Headlines_Dataset.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Call the function to process the JSON file\u001b[39;00m\n\u001b[32m     33\u001b[39m satire_df = pd.DataFrame(columns=[\u001b[33m\"\u001b[39m\u001b[33mheadline\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m satire_df = \u001b[43mprocess_sarcasm_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43msatire_source_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSarcasm_Headlines_Dataset.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msatire_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mprocess_sarcasm_json\u001b[39m\u001b[34m(json_file, df)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mProcesses the Sarcasm_Headlines_Dataset.json file, extracting headlines \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03mthat are sarcastic (is_sarcastic == 1), and appends them to the given DataFrame.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[33;03m    DataFrame: The updated DataFrame containing sarcastic headlines.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     15\u001b[39m new_rows = []\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(file, \u001b[32m1\u001b[39m):  \u001b[38;5;66;03m# Track line numbers\u001b[39;00m\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './Data_Exploration/Satire_HeadLines_Source/Sarcasm_Headlines_Dataset.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def process_sarcasm_json(json_file, df):\n",
    "    \"\"\"\n",
    "    Processes the Sarcasm_Headlines_Dataset.json file, extracting headlines \n",
    "    that are sarcastic (is_sarcastic == 1), and appends them to the given DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        json_file (str): The path to the JSON file containing sarcastic headlines.\n",
    "        df (DataFrame): The DataFrame to which sarcastic headlines will be added.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: The updated DataFrame containing sarcastic headlines.\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        for i, line in enumerate(file, 1):  # Track line numbers\n",
    "            try:\n",
    "                entry = json.loads(line.strip())  # strip to avoid extra spaces\n",
    "                if entry.get(\"is_sarcastic\") == 1:  # Safely access the key\n",
    "                    new_rows.append({\"headline\": entry[\"headline\"]})\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line {i}: {e}\")\n",
    "                print(f\"Line {i} content: {line.strip()}\")\n",
    "                continue  # Skip the problematic line\n",
    "    \n",
    "    new_df = pd.DataFrame(new_rows)\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "satire_source_path = \"./Data_Exploration/Satire_HeadLines_Source/\"\n",
    "# Call the function to process the JSON file\n",
    "satire_df = pd.DataFrame(columns=[\"headline\"])\n",
    "satire_df = process_sarcasm_json(satire_source_path + \"Sarcasm_Headlines_Dataset.json\", satire_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fix_json_format(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Remove leading/trailing whitespaces and empty lines\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "\n",
    "    # Start the JSON array\n",
    "    fixed_content = '[' + '\\n'\n",
    "\n",
    "    # Join the cleaned lines with commas and add them to the array\n",
    "    fixed_content += ',\\n'.join(cleaned_lines)\n",
    "\n",
    "    # End the JSON array\n",
    "    fixed_content += '\\n]'\n",
    "\n",
    "    # Write the fixed content to a new file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(fixed_content)\n",
    "\n",
    "# Example usage\n",
    "fix_json_format('./Data_Exploration/Satire_HeadLines_Source/Sarcasm_Headlines_Dataset.json', './Data_Exploration/Satire_HeadLines_Source/Fixed_Sarcasm_Headlines_Dataset.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
